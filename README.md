The current model was trained in about 2 minutes on my laptop and had about an 80% accuracy on the MNIST test dataset. 

This model isn't a very deep network, but changing the layer hyper-parameters (the n array) will allow you arbitrarily add as many layers as you want, and you can even swap out the activation functions too. The model could be made significantly more accurate with more layers but I don't have the equipment to train/experiment with that size a model in a reasonable timeframe.
